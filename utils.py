import tiktoken
from typing import List, Tuple, Sequence, Any
import numpy as np
import pandas as pd


def eval_on_unseen_train(
    func=None,
    spams:Sequence[str]=None,
    normals:Sequence[str]=None,
    n_context_examples:int=-1     
)->Tuple[float, float, str, str]:
    assert func is not None
    assert spams is not None 
    assert normals is not None
    assert n_context_examples >= 0
    assert n_context_examples<len(spams) and n_context_examples<len(normals)
    
    spams, normals = map(pd.Series, [spams, normals])
    tp_1, tp_2 = spams.apply(func).sum(), len(spams) 
    fp_1, fp_2 = normals.apply(func).sum(), len(normals)
    tp = (tp_1-n_context_examples) / (tp_2-n_context_examples)
    tpmsg = f"{tp_1-n_context_examples} / {tp_2-n_context_examples}"
    fp = (fp_1-n_context_examples) / (fp_2-n_context_examples)
    fpmsg = f"{fp_1-n_context_examples} / {fp_2-n_context_examples}"

    return round(tp,3), round(fp,3), tpmsg, fpmsg

def refine_code(code:str):
    if "```python" in code:
        print('refine_code was actually needed!')
        code = code.split('```python')[1]
        code = code.split('```')[0]
    return code

def make_minibatches(whole:Sequence, bsz=10)->Sequence[Sequence]:
    batched = [whole[start:start+bsz] for start in range(0, len(whole), bsz)]
    if len(batched)>1:
        if len(batched[-1])< len(batched[-2]):
            batched.pop() # remove dangling minibatch to improve prompt quality
    return batched

def count_token(txt, model='gpt-4'): # gpt-3.5-turbo
    # returning 0 if txt is not a string
    enc = tiktoken.encoding_for_model("gpt-4")
    return len(enc.encode(txt)) if isinstance(txt, str) else 0


def get_exerpt(longtxt:str, toklength:int=80, delim:str='\n')->Tuple[str, int]:
    # if the message is too long, divide it into pieces and pick one as its representation.
    if delim not in longtxt:
        return longtxt

    spls = longtxt.split(delim)
    spl_lens = [count_token(sp) for sp in spls]
    indices, newlengths = chunk_lengths(spl_lens, threshold=toklength)
    pick = np.random.randint(len(indices))


    span = indices[pick]
    l:int = newlengths[pick]
    excerpt:str = "\n".join(spls[span[0]:span[1]+1])
    # print(f"{spls=}")
    # print(f"{indices=}")
    # print(f"{newlengths=}")
    # print(f"{pick=}")
    # print(f"{excerpt=}")
    return excerpt, l
   


def chunk_lengths(lengths: List[int], threshold: int) -> Tuple[Sequence[Tuple[int, int]], Sequence[int]]:
    def variance(l: List[int]) -> float:
        return abs(sum(l) - threshold)

    i = 0
    merged_indices = []
    new_lengths = []

    while i < len(lengths):
        current_chunk = [lengths[i]]
        j = i + 1

        if j < len(lengths):
            temp_chunk = current_chunk + [lengths[j]]
            if variance(temp_chunk) <= variance(current_chunk):
                current_chunk = temp_chunk
                merged_indices.append((i, j))
                i = j + 1
            else:
                merged_indices.append((i, i))
                i = j
        else:
            merged_indices.append((i, i))
            i = j

        new_lengths.append(sum(current_chunk))

    return merged_indices, new_lengths


txt='''
"[Webë°œì‹ ]
ì§€ë‚œì£¼ ì¶”ì²œì£¼ í˜„í™©
-ë”ë©”í‹°íŒœ42%â†‘
-ì¡°ì„ ì•Œë¯¸ëŠ„26%â†‘

3ì£¼ì°¨ ì¢…ëª© ë‚´ì¼ë¶€í„°
https://me2.kr/mjp

[Webë°œì‹ ]
ê¸ˆì¼ë¶€í„° ""4ì›”VIPíˆ¬ìë°˜"" ì‹œì‘
ì°¨ë³„í™” ëœ ë¶„ì„/ì¶”ì²œ/ì‹œí™©
ì‹¤ë ¥ìœ¼ë¡œ ì…ì¦
https://me2.kr/mjp
â–²

[Webë°œì‹ ]
""ì´ë°©ë²• í•˜ë‚˜ë©´
100,000ì› ìœ¼ë¡œ
ì£¼ 2,720,000ì› ì„±ê³µ
ë¬´ë£Œì²´í—˜â–¼
https://dokdo.in/p7

[Webë°œì‹ ]
ì—¬ì˜ë„ì‚¬ëŒë“¤4ì›”ì²´í—˜ë°˜
https://me2.kr/mjp
-ì •í™•í•œ ë¶„ì„/íƒ€ì 
-ê²€ì¦ëœ ìˆ˜ìµë¥ 
-ì¢…ëª©ìƒë‹´/ì¶”ì²œ

[Webë°œì‹ ]
18ì¼ ê¸´ê¸‰ì…ìˆ˜ì •ë³´
Cì œì•½, íƒˆëª¨ì¹˜ë£Œì œ êµ­ë‚´ì‹ì•½ì²˜ ì •ì‹í—ˆê°€ì„ë°•
ìƒí•œê°€ í™•ì •
https://me2.kr/mjp

[Webë°œì‹ ]
ì •ë³´ë°© ì•ˆë‚´

ì´ˆëŒ€í•´ë“œë¦½ë‹ˆë‹¤!
200ë°›ê³  ì‹œì‘í•˜ì„¸ìš”

https://vvd.bz/b8W0

[Webë°œì‹ ]
FROG 4ì›”3ì£¼ì°¨VIPë¬´ë£Œì²´í—˜ë°˜
15ë…„ ì—°í˜ì˜ ì²­ê°œêµ¬ë¦¬í•µì‹¬ì •ë³´ë¥¼ ëª¨ë‘ ë¬´ë£Œë¡œ!
https://me2.kr/tlk

[Webë°œì‹ ]
ì˜¤í›„ë¶€í„° ì‹œì‘í•˜ëŠ” VIPì²´í—˜ë°˜ì…ë‹ˆë‹¤
ì—¬ì˜ë„ë¶€ì¥ë“¤ì˜ íƒ€ì /ë¶„ì„ì„ í•œëˆˆì—!
https://me2.kr/bk2"'''
# print(txt)
# for i in range(3):
#     print(get_exerpt(txt))

# test chunk_lengths
# lengths = [4, 5, 20, 3, 12, 3, 10]
# threshold = 12
# indices, new_lengths = chunk_lengths(lengths, threshold)

# print("Indices:", indices)
# print("Lengths:", new_lengths)




# TXT = '''- [êµ­ì œë°œì‹ ]
# slotğŸ°zone

# â˜ì²˜ìŒí˜œíƒ
# 10 +3O% +2

# ğŸ€ë§¤ì¼ì²« +15%

# ğŸ’(ì½¤0.8%,í˜ë°±10%)

# â“¢lâ“©102.com
# - [Webë°œì‹ ] ê¸ˆê°’ ì‚¬ìƒ ìµœê³ ê°€ ê²½ì‹  30ë§Œ ì‹œì‘ 1780ë§Œ ë§ˆê°
# - [Webë°œì‹ ]
#  ë‹˜

# ì‹  ì²­ í•˜ ì‹  

# ì…ì¥ ì•ˆë‚´ ë“œë¦½ë‹ˆë‹¤.

# openkakao.io/Wscz
# - [Webë°œì‹ ]
# bit.ly/3KGQVIV
# vipì£¼,ì‹ ì„¸,ë ¥ ë‹¨,íƒ€ 1ì¼1ë§¤ë„
# ë¬´ë£Œë°© ì…ë‹ˆë‹¤
# 3ì¼ë§Œ ì§€ì¼œë³´ì„¸ìš”
# - ì§€ë‚œì£¼ ì¶”ì²œì£¼ í˜„í™©
# - ë‹¨íƒ€ì •ë³´íŠ¸ë ˆì´ë”©
# - ìƒŒì¦ˆ vip ë‹¨íƒ€ í­ë“± ê¸°ë²• ì•„ì¤Œë§ˆ ë¹„ë°€ ê³µì‹œê³µê°œ ì˜¤í”ˆì´ˆëŒ€ í•´ì„  ë‹¨ì²´ë°©
# - [Webë°œì‹ ]
# (ê´‘ê³ )íŠ¹ë³„ì°¬ìŠ¤ì¡ìœ¼ì„¸ìš”

# â–’  ëŒ€í˜•  Major ã€ ëª…-ê°€ ã€
# ****************************
# â–’ ì„¸ê³„ NO.1 ì´ˆlê³  ã…‚.Hë‹¹
# ****************************

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

#  â–¶ LIVE CA.ã…ˆlë…¸ ì ë¦½ê¸ˆ

#     => ã…‚.HíŒ… ê¸ˆì•¡ 1% ì ë¦½ â™¥

#  â–¶ ê°ì¢… ã…lã„´l GAME

#      => 1 . 9 8  ã…‚.Hë‹¹ â™¥

#  â–¶ ë°”ï¼»CAï¼½ã„¹.r

#      => 2 . Î˜ 1 ã…‚.Hë‹¹ â™¥

#  â€» ê¼­ ë¹„êµ í•œë²ˆ ë¶€íƒë“œë¦½ë‹ˆë‹¤

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

# â–© ë©”ê°€ C.A.S.H ë“œë 
#          â†“   â†“   â†“
#   ë§¤ì¼ë§¤ì¼ ï¼‘ÎŸÎŸ ë§Œì› ì§€ê¸‰
#   ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£
# â–© ì²˜ ìŒ ë°© ë¬¸ ì‹œ  â™¥
#          â†“   â†“   â†“
#    3+2  5+3  10+5  20+7
#   ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£
#    30+10 50+15 100+30
#   ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£

#  â€» ê²Œì‹œíŒ í•„íˆ í™•ì¸í•´ì£¼ì„¸ìš”.

#  ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼

# ã€ ëª…-ê°€ ã€‘ ìƒˆ ê°€ì¡±ë¶„ë“¤ì„ ìœ„í•´
# ì¤€ë¹„í•œ ê²ƒë“¤ì„ ê¼­ ë°›ì•„ê°€ì„¸ìš”

# â–¶ë°©ë¬¸ :  mâ“–-zxc.com

# â–¶Key  :  3030

#  ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼

#  â™¥ ì¤€ ë¹„ ëœ ê²Œ ì„ ë“¤
#     ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£ï¿£
#  â€» ì‹¤..ì‹œ..ê°„..ë¼..ì´..ë¸Œ

#  â€» ì—..ë³¼..ë£¨..ì…˜

#  â€» ë™..í–‰..ê°€..ìƒ

#  â€» ë¯¸..ë‹ˆ..ê²Œ..ì„

#  â€» Mì¥M & LOíˆ¬S

#  ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼

# â€» ë¶ˆí¸í•œ ê·œì •ê³¼ ì œì¬ë¥¼ ê³¼ê°íˆ
#    ì—†ì— ë²„ë ¸ìŠµë‹ˆë‹¤

# â€» (ìœ )ì¶œ ë° (ì¡°)ì‘ ë“± í—›ì†Œë¦¬ë¥¼
#    í•˜ì§€ ì•Šê² ìŠµë‹ˆë‹¤

# â€» ì¶©(í™˜)ì— ìˆì–´ ë¹ ë¥´ê³  ì‹ ì†í•˜ê²Œ
#    ëŒ€ì²˜í•˜ê² ìŠµë‹ˆë‹¤

# â€» ë©ˆì¶°ìˆì§€ ì•Šê³  í•­ìƒ ìƒˆë¡œìš´
#    ì´ë²¤íŠ¸ë“¤ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤

#  ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼

# ã€ ëª…-ê°€ ã€‘ ìƒˆ ê°€ì¡±ë¶„ë“¤ì„ ìœ„í•´
# ì¤€ë¹„í•œ ê²ƒë“¤ì„ ê¼­ ë°›ì•„ê°€ì„¸ìš”

# â–¶ë°©ë¬¸ :  mâ“–-zxc.com

# â–¶Key  :  3030

#  ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼ ï¼

# ã‰¿Â±âˆÎ˜Â¾


# ë¬´ë£Œìˆ˜ì‹ ê±°ë¶€ 0808550128
# ì¸ì¦ë²ˆí˜¸ 628
# - [Webë°œì‹ ]
# ë‹˜

# ì‹  ì²­ í•˜ ì‹  

# ì…ì¥ ì•ˆë‚´ ë“œë¦½ë‹ˆë‹¤.

# openkakao.io/Wscz
# - [Webë°œì‹ ]
# ë‹˜
# ì‹ ì²­í•˜ì‹  ë°© 
# ì…ì¥ í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤

# kakaotalk.it/E8sc
# - [Webë°œì‹ ]
# ë‹˜ ì‹ ì²­í•˜ì‹  ë°©
# ì…ì¥ ì•ˆë‚´ ë“œë¦½ë‹ˆë‹¤

# kakaotalk.it/gd7q
# - [Web ê·¸ë£¹]
# ìƒìƒê·¸ë£¹
# ì¹´>ì—ë³¼go.com

# ì§€>ì‹ ê·œê°ì‚¬ì¿ í°

# ë…¸>ì‹ ê·œ 5ë§Œì›
# - [Webë°œì‹ ]
# ì„  ë¬¼ ì˜µ ì…˜
# ê²½ì œì  ììœ ë¥¼í–¥í•´
# ì´ˆì‹¬ë¶€í„° ì‹¬í™”ê³¼ì • êµìœ¡
# â–¼ë‹¨ í•˜ë£¨ ì…ì¥â–¼
# fste.in/hsh2
# - ì¶•í•˜í•©ë‹ˆë‹¤, ì‹ ì²­í•˜ì‹  VIPì— ì„ ì •ë˜ì…¨ìŠµë‹ˆë‹¤.
# ì–¸ë¡ ì‚¬ ë¯¸ê³µê°œ ê³µì‹œì¢…ëª© ê³µê°œ
# ê·¹ë¹„ ì‘ì „ì£¼ ì„ ì°©ìˆœ ê³µê°œ
# - [Webë°œì‹ ]
# ë¼ì¹¸â˜…

# ë§¤ì¼15%ì½¤í“¨2%

# ì²˜ìŒ40%
# ì£¼1íšŒ=BBQ+í”¼ì+í™œì¿±
# ì „í™”X

# í†¡uo119
# abit.ly/itxja
# ì½”ë“œ:ìë™
# - ë„¤
# - [Webë°œì‹ ]
# [ì±„íŒ…ë°© ì¢…ë£Œì•ˆë‚´]
# *í†µí•©ìš´ì˜
# *500ëª… ì œí•œì°¸ì—¬
# *ê¸°ì¡´ì •ë³´/í˜œíƒìœ ì§€
# â–¼â–¼
# http://ì‹ ê·œí†µí•©ë°©.com
# - [Webë°œì‹ ]
# (ê´‘ê³ )
# ì´íš¨ì‹ë§¤ë‹ˆì €
# ì‹ ë…„ë§ì´ ëª¨ì§‘
# ë¹„íŠ¸/ë‹¨íƒ€ê±°ë˜
# ocx.kr/3gYlA
# ì•”í˜¸1133
# ë¬´ë£Œê±°ë¶€  0801364481
# - [Webë°œì‹ ]
# ë§Œì›ìœ¼ë¡œ ë°±ë§Œì› ë‹¬ì„±
# url.kr/xcul67
# '''

# EN = """Act as a skilled programmer using regex to process massive bunch of text data. Please write a python function that correctly classifies the above spam messages from the normal ones. Mind that the function should not overfit to the examples above. The name of the function is <code>is_spam</code>. Be cautious not to detect them whether they starts with [Webë°œì‹ ] or not. You don't need to implement the test code of it."""
# CODE = '''

# def is_spam(text):
#     # Define regular expressions to match common patterns in spam messages
#     regex_list = [
#         r'http\S+',  # URLs
#         r'[ê°€-í£]*[A-Z]+[ê°€-í£]*',  # Korean text including English words in all caps
#         r'\d{4}ë…„\d{1,2}ì›”\d{1,2}ì¼',  # Date in the format of YYYYë…„MMì›”DDì¼
#         r'\d{1,2}:\d{1,2}:\d{1,2}',  # Time in the format of HH:MM:SS
#         r'ìƒí•œê°€|ì¢…ëª©|ê³µì‹œ|ë§¤ìˆ˜|ë§¤ë„|í­ë“±|í­ë½',  # Keywords related to stock trading
#         r'vip|vvip',  # Keywords related to exclusive memberships
#         r'ì „í™”|ë¬¸ì',  # Keywords related to communication
#         r'ì¶•í•˜|ê±´ê°•|ìƒì‹ |ìƒì¼',  # Keywords related to celebrations or greetings
#         r'ì„œìš¸êµí†µê³µì‚¬|êµí†µì¹´ë“œ',  # Keywords related to public transportation
#         r'LH|ì„±ë‚¨ë³µì •',  # Keywords related to real estate or housing
#         r'ë‹¨ë…ì œíœ´',  # Keywords related to exclusive partnerships
#         r'ì‹ ì²­',  # Keywords related to applications or registrations
#         r'ê¸°ì—…ê³¼',  # Keywords related to business deals or collaborations
#         r'ë¶„ì„|ì¶”ì²œ|ì‹œí™©',  # Keywords related to stock analysis or recommendations
#         r'ê¸ˆì¼ë¶€í„°|ì‹œì‘',  # Keywords related to time-sensitive events or promotions
#         r'ê´‘ê³ |ì•ˆë‚´|í™ë³´|ì´ë²¤íŠ¸|í• ì¸|í˜œíƒ',  # Keywords related to advertising or promotions
#         r'ê³µì§œ|ë¬´ë£Œ|ì¦ì •|ì„ ì°©ìˆœ',  # Keywords related to freebies or giveaways
#     ]
    
#     # Define a regular expression to match any of the above patterns
#     spam_regex = re.compile('|'.join(regex_list), re.IGNORECASE)
    
#     # Check if the text matches the spam pattern
#     return bool(spam_regex.search(text))

# df = pd.read_csv('spam_data_v0.csv')
# res_spam_normal = f"{df.spam.apply(is_spam).sum()} / {len(df)}, {df.normal.apply(is_spam).sum()}/{len(df)}"
# print(res_spam_normal)
# '''


# print(count_token('spam message examples'))
# print(count_token(TXT))
# print(len(TXT.strip().split())) # factor 5 for korean sms

# print(count_token(CODE))
# print(len(CODE.strip().split())) # factor 5 for korean sms

# print(count_token(EN))
# print(len(EN.strip().split())) # factor 5 for korean sms
